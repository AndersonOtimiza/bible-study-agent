# Guia de Configura√ß√£o GPU/CUDA

Este guia explica como habilitar e configurar o uso de GPU para acelerar o processamento no Bible Study Agent.

## üéØ Requisitos

- **GPU NVIDIA** com suporte a CUDA (GTX/RTX 10xx ou superior)
- **CUDA Toolkit** instalado (vers√£o 11.8 ou 12.x)
- **NVIDIA Driver** atualizado
- **Windows/Linux** com Python 3.10+

## üì¶ Instala√ß√£o

### 1. Verificar GPU Dispon√≠vel

Execute o script de verifica√ß√£o:

```bash
python scripts/check_gpu.py
```

Este script mostrar√°:
- ‚úÖ Status do PyTorch e CUDA
- ‚úÖ GPUs detectadas e suas especifica√ß√µes
- ‚úÖ Mem√≥ria dispon√≠vel
- ‚úÖ Status do FAISS
- üí° Recomenda√ß√µes de configura√ß√£o

### 2. Instalar PyTorch com CUDA

**Para CUDA 12.4:**
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124
```

**Para CUDA 11.8:**
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

**Verificar vers√£o CUDA instalada:**
```bash
nvcc --version
# ou
nvidia-smi
```

### 3. Instalar FAISS-GPU (Opcional, mas recomendado)

FAISS-GPU acelera drasticamente a busca de similaridade.

**Via Conda (recomendado):**
```bash
conda install -c pytorch faiss-gpu
```

**Via pip (experimental):**
```bash
pip install faiss-gpu
```

## ‚öôÔ∏è Configura√ß√£o

### Arquivo `.env`

Copie o arquivo de exemplo:
```bash
copy .env.example .env
```

Configure as seguintes vari√°veis:

```env
# Habilitar FAISS em GPU
USE_FAISS_GPU=1

# Controle do device PyTorch
TORCH_DEVICE=auto  # ou 'cuda' para for√ßar GPU

# Opcional: limitar mem√≥ria GPU para FAISS (em GB)
# FAISS_GPU_MEMORY_LIMIT=4
```

## üöÄ Uso

### Iniciar o Servidor

Com GPU configurada, basta iniciar normalmente:

```bash
python src/app.py
```

Ou com uvicorn:

```bash
uvicorn src.app:app --host 0.0.0.0 --port 8000 --reload
```

### Verificar Status

Ao iniciar, voc√™ ver√° logs indicando uso de GPU:

```
Carregando modelo paraphrase-multilingual-mpnet-base-v2...
‚úì Modelo carregado na GPU: NVIDIA GeForce RTX 3080
  ‚Ä¢ Mem√≥ria GPU: 10.00 GB
  ‚Ä¢ CUDA Version: 12.4
```

## üîç Monitoramento

### Monitorar Uso de GPU

**Windows:**
```powershell
nvidia-smi -l 1
```

**Linux:**
```bash
watch -n 1 nvidia-smi
```

### Verificar Mem√≥ria GPU em Python

```python
import torch

if torch.cuda.is_available():
    print(f"GPU: {torch.cuda.get_device_name(0)}")
    print(f"Mem√≥ria Alocada: {torch.cuda.memory_allocated(0)/1024**3:.2f} GB")
    print(f"Mem√≥ria Reservada: {torch.cuda.memory_reserved(0)/1024**3:.2f} GB")
```

## üìä Performance Esperada

### Sem GPU (CPU)
- **Embedding**: ~100 versos/segundo
- **Busca FAISS**: ~50ms por query (7.927 versos)

### Com GPU
- **Embedding**: ~500-1000 versos/segundo (5-10x mais r√°pido)
- **Busca FAISS**: ~5-10ms por query (5-10x mais r√°pido)
- **LLM Inference**: Depende do modelo e quantiza√ß√£o

## üêõ Troubleshooting

### "CUDA out of memory"

**Solu√ß√£o 1:** Limpar cache
```python
import torch
torch.cuda.empty_cache()
```

**Solu√ß√£o 2:** Reduzir batch size no `.env`
```env
FAISS_GPU_MEMORY_LIMIT=4
```

**Solu√ß√£o 3:** Usar CPU para FAISS
```env
USE_FAISS_GPU=0
```

### "CUDA not available"

1. Verificar se CUDA est√° instalado:
   ```bash
   nvcc --version
   ```

2. Verificar driver NVIDIA:
   ```bash
   nvidia-smi
   ```

3. Reinstalar PyTorch com CUDA:
   ```bash
   pip uninstall torch torchvision torchaudio
   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124
   ```

### FAISS n√£o detecta GPU

FAISS-GPU requer instala√ß√£o via conda:
```bash
conda install -c pytorch faiss-gpu
```

Ou compile manualmente com suporte a CUDA.

## üéõÔ∏è Configura√ß√µes Avan√ßadas

### M√∫ltiplas GPUs

Para usar GPU espec√≠fica:

```python
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # Usar apenas GPU 0
```

Ou no `.env`:
```env
CUDA_VISIBLE_DEVICES=0,1  # Usar GPUs 0 e 1
```

### Mixed Precision (FP16)

Para reduzir uso de mem√≥ria:

```env
TORCH_DTYPE=float16
```

(Requer modifica√ß√£o no c√≥digo para suportar)

## üìö Links √öteis

- [NVIDIA CUDA Toolkit](https://developer.nvidia.com/cuda-downloads)
- [PyTorch Installation](https://pytorch.org/get-started/locally/)
- [FAISS GPU Guide](https://github.com/facebookresearch/faiss/wiki/Faiss-on-the-GPU)
- [Sentence Transformers GPU](https://www.sbert.net/docs/usage/semantic_textual_similarity.html)

## ‚úÖ Checklist R√°pido

- [ ] GPU NVIDIA instalada e funcionando
- [ ] CUDA Toolkit instalado (nvcc --version)
- [ ] Driver NVIDIA atualizado (nvidia-smi)
- [ ] PyTorch com CUDA instalado
- [ ] FAISS-GPU instalado (opcional)
- [ ] `.env` configurado com USE_FAISS_GPU=1
- [ ] Script `check_gpu.py` executado com sucesso
- [ ] Servidor iniciado e logs mostram GPU ativa

---

**üéâ Pronto!** Seu sistema agora usa GPU para m√°xima performance.
